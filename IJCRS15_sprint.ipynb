{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import os.path as op\n",
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root working dir: /Users/alexandre/data/coal_mining\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "\n",
    "hn = socket.gethostname()\n",
    "\n",
    "if hn == 'AyerdiBorja':\n",
    "    datadir = '/Users/ayerdi/Desktop/data'\n",
    "    resultDir = '/Users/ayerdi/Desktop/Dropbox (Neurita)/IJCRS15_code'\n",
    "elif hn == 'calm.local':\n",
    "    root_dir  = op.expanduser('~/data/coal_mining')\n",
    "    datadir   = op.join(root_dir, 'data')\n",
    "    resultDir = op.join(root_dir, 'results')\n",
    "    hdf_file  = op.join(root_dir, 'coal_mining_data.hdf')\n",
    "    test_csv_file = op.join(datadir, 'testData.csv')\n",
    "    \n",
    "    \n",
    "print('Root working dir: {}'.format(root_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Total Warnings: 1429\n",
    "# Total Warnings 1: 80\n",
    "# Total Warnings 2: 1208\n",
    "# Total Warnings 3: 141\n",
    "# Total Normal: 118571\n",
    "# Acc. all normal: 0.988091666667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_csv_test_data(filepath=test_csv_file):\n",
    "    return pd.read_csv(filepath, sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_csv_training_data():\n",
    "\n",
    "    X = pd.DataFrame()\n",
    "    Y = pd.DataFrame()\n",
    "\n",
    "    for i in range(1,5):\n",
    "        trainFile = 'trainingData' + str(i) + '.csv'\n",
    "        testFile = 'trainingLabels' + str(i) + '.csv'\n",
    "\n",
    "        print('Reading data from {}'.format(trainFile))\n",
    "    \n",
    "        # Load training data\n",
    "        train = os.path.join(datadir, trainFile)\n",
    "        train = pd.read_csv(train, sep=',', header=None)\n",
    "\n",
    "        # Load labels\n",
    "        labels = os.path.join(datadir, testFile)\n",
    "        labels = pd.read_csv(labels, sep=',', header=None)\n",
    "        label_0 = (labels[0] == 'warning') *1\n",
    "        label_1 = (labels[1] == 'warning') *1\n",
    "        label_2 = (labels[2] == 'warning') *1\n",
    "        y = pd.concat([label_0, label_1, label_2], axis=1)\n",
    "\n",
    "        X = pd.concat([X, train])\n",
    "        Y = pd.concat([Y, y])\n",
    "\n",
    "\n",
    "    X = X.reset_index()\n",
    "    X = X.drop('index',1)\n",
    "\n",
    "    Y = Y.reset_index()\n",
    "    Y = Y.drop('index',1)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save to hdf file\n",
    "# you need to install PyTables for this: !pip install tables\n",
    "def convert_csv_to_hdf(hdf_filepath=hdf_file):\n",
    "    print('Reading test data.')\n",
    "    test_data = read_csv_test_data()\n",
    "\n",
    "    print('Reading training data.')\n",
    "    train_samples, train_labels = read_csv_training_data()\n",
    "\n",
    "    print('Saving data into {}'.format(hdf_filepath))\n",
    "    test_data.to_hdf    (hdf_filepath, key='test_data')\n",
    "    train_samples.to_hdf(hdf_filepath, key='samples')\n",
    "    train_labels.to_hdf (hdf_filepath, key='labels')\n",
    "\n",
    "\n",
    "def read_data_from_hdf(hdf_filepath=hdf_file):\n",
    "    test_data     = pd.read_hdf(hdf_filepath, key='test_data')\n",
    "    train_samples = pd.read_hdf(hdf_filepath, key='samples')\n",
    "    train_labels  = pd.read_hdf(hdf_filepath, key='labels')\n",
    "    return test_data, train_samples, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove hdf file\n",
    "#!rm $hdf_file\n",
    "#convert_csv_to_hdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the data from HDF file\n",
    "test_data, train_samples, train_labels = read_data_from_hdf(hdf_filepath=hdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ya tenemos todos los datos en X e Y, ahora toca usar la imaginaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 16800)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
